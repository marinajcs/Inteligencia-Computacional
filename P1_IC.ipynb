{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvwUMG2MeEQB",
        "outputId": "61aba297-8138-404a-c3d1-6d456504f636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTS Y FUNCIONES COMUNES"
      ],
      "metadata": {
        "id": "dcqy_zgo3zwo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "odKzB_YGwI56"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def cargar_train_imgs():\n",
        "    with open('/content/drive/MyDrive/IC/samples/train-images.idx3-ubyte', 'rb') as f:\n",
        "        f.read(16)  # Descartar cabecera\n",
        "        images = []\n",
        "        while True:\n",
        "            image = f.read(784)\n",
        "            if len(image) != 784:\n",
        "                break\n",
        "            images.append([x for x in image])\n",
        "    return np.array(images)\n",
        "\n",
        "def cargar_test_imgs():\n",
        "    with open('/content/drive/MyDrive/IC/samples/t10k-images.idx3-ubyte', 'rb') as f:\n",
        "        f.read(16)  # Descartar cabecera\n",
        "        images = []\n",
        "        while True:\n",
        "            image = f.read(784)\n",
        "            if len(image) != 784:\n",
        "                break\n",
        "            images.append([x for x in image])\n",
        "    return np.array(images)\n",
        "\n",
        "def cargar_train_labels():\n",
        "    with open('/content/drive/MyDrive/IC/samples/train-labels.idx1-ubyte', 'rb') as f:\n",
        "        f.read(8)  # Descartar cabecera\n",
        "        etiquetas = [x for x in f.read()]\n",
        "    return np.array(etiquetas)\n",
        "\n",
        "def cargar_test_labels():\n",
        "    with open('/content/drive/MyDrive/IC/samples/t10k-labels.idx1-ubyte', 'rb') as f:\n",
        "        f.read(8)  # Descartar cabecera\n",
        "        etiquetas = [x for x in f.read()]\n",
        "    return np.array(etiquetas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uDrfsfwt20X0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Cargar los datos\n",
        "train_images = cargar_train_imgs()\n",
        "train_labels = cargar_train_labels()\n",
        "test_images = cargar_test_imgs()\n",
        "test_labels = cargar_test_labels()\n",
        "\n",
        "# Preprocesar los datos de entrenamiento (Normalizar y convertir etiquetas)\n",
        "train_images = train_images / 255.0  # rango [0, 1]\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "\n",
        "# Preprocesar los datos de prueba (Normalizar y convertir etiquetas)\n",
        "test_images = test_images / 255.0  # rango [0, 1]\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "train_images = train_images.reshape(-1, 28, 28, 1)  # '1': el canal (blanco y negro)\n",
        "test_images = test_images.reshape(-1, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZiZO8nClPl5"
      },
      "source": [
        "# Red neuronal simple (NN-1)\n",
        "\n",
        "Con una capa de entrada y una capa de salida de tipo softmax."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "t_qCN9qmD1Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqRCg7q10lGQ",
        "outputId": "a58deec5-b327-4eac-ee2b-0e68443ac65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 - 3s - 2ms/step - accuracy: 0.8780 - loss: 0.4666\n",
            "Epoch 2/10\n",
            "1875/1875 - 2s - 1ms/step - accuracy: 0.9143 - loss: 0.3040\n",
            "Epoch 3/10\n",
            "1875/1875 - 2s - 1ms/step - accuracy: 0.9213 - loss: 0.2832\n",
            "Epoch 4/10\n",
            "1875/1875 - 3s - 2ms/step - accuracy: 0.9236 - loss: 0.2734\n",
            "Epoch 5/10\n",
            "1875/1875 - 3s - 2ms/step - accuracy: 0.9256 - loss: 0.2669\n",
            "Epoch 6/10\n",
            "1875/1875 - 4s - 2ms/step - accuracy: 0.9271 - loss: 0.2618\n",
            "Epoch 7/10\n",
            "1875/1875 - 3s - 1ms/step - accuracy: 0.9280 - loss: 0.2583\n",
            "Epoch 8/10\n",
            "1875/1875 - 3s - 1ms/step - accuracy: 0.9291 - loss: 0.2549\n",
            "Epoch 9/10\n",
            "1875/1875 - 3s - 2ms/step - accuracy: 0.9300 - loss: 0.2529\n",
            "Epoch 10/10\n",
            "1875/1875 - 2s - 1ms/step - accuracy: 0.9308 - loss: 0.2507\n",
            "Tiempo de entrenamiento: 30.18 segundos\n",
            "Error de entrenamiento: 6.98%\n",
            "Error de prueba: 7.39%\n"
          ]
        }
      ],
      "source": [
        "# Crear modelo\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28, 1)),  # Aplanar las imágenes\n",
        "    Dense(10, activation='softmax')   # Capa de salida softmax\n",
        "])\n",
        "\n",
        "# Compilar modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Entrenar modelo\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    verbose=2)\n",
        "\n",
        "# Calcular el tiempo de entrenamiento\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"Tiempo de entrenamiento: {training_time:.2f} segundos\")\n",
        "\n",
        "# Evaluar el modelo en el conjunto de entrenamiento y el de prueba\n",
        "train_loss, train_acc = model.evaluate(train_images, train_labels, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
        "\n",
        "# Calcular y mostrar los errores\n",
        "train_error = 100 - train_acc * 100\n",
        "test_error = 100 - test_acc * 100\n",
        "print(f\"Error de entrenamiento: {train_error:.2f}%\")\n",
        "print(f\"Error de prueba: {test_error:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F6vq1sK0JUr"
      },
      "source": [
        "# Red neuronal multicapa (NN-2)\n",
        "\n",
        "Con una capa oculta de 256 unidades logísticas y una capa de salida de tipo softmax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6af5hcPB1WMq",
        "outputId": "c83ac2fa-cb22-426d-c4d2-16e3d533c0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 - 5s - 3ms/step - accuracy: 0.9344 - loss: 0.2237\n",
            "Epoch 2/10\n",
            "1875/1875 - 2s - 1ms/step - accuracy: 0.9722 - loss: 0.0935\n",
            "Epoch 3/10\n",
            "1875/1875 - 3s - 1ms/step - accuracy: 0.9807 - loss: 0.0623\n",
            "Epoch 4/10\n",
            "1875/1875 - 3s - 1ms/step - accuracy: 0.9863 - loss: 0.0440\n",
            "Epoch 5/10\n",
            "1875/1875 - 3s - 2ms/step - accuracy: 0.9897 - loss: 0.0333\n",
            "Epoch 6/10\n",
            "1875/1875 - 3s - 2ms/step - accuracy: 0.9918 - loss: 0.0244\n",
            "Epoch 7/10\n",
            "1875/1875 - 4s - 2ms/step - accuracy: 0.9937 - loss: 0.0196\n",
            "Epoch 8/10\n",
            "1875/1875 - 3s - 1ms/step - accuracy: 0.9951 - loss: 0.0157\n",
            "Epoch 9/10\n",
            "1875/1875 - 3s - 2ms/step - accuracy: 0.9964 - loss: 0.0121\n",
            "Epoch 10/10\n",
            "1875/1875 - 3s - 2ms/step - accuracy: 0.9962 - loss: 0.0111\n",
            "Tiempo de entrenamiento: 32.59 segundos\n",
            "Error de entrenamiento: 0.20%\n",
            "Error de prueba: 1.78%\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28, 1)),\n",
        "    Dense(256, activation='relu'),   # Capa oculta de 256 unidades logísticas\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    verbose=2)\n",
        "\n",
        "# Calcular el tiempo de entrenamiento\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"Tiempo de entrenamiento: {training_time:.2f} segundos\")\n",
        "\n",
        "# Evaluar el modelo en el conjunto de entrenamiento completo\n",
        "train_loss, train_acc = model.evaluate(train_images, train_labels, verbose=0)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
        "\n",
        "# Calcular y mostrar los errores\n",
        "train_error = 100 - train_acc * 100\n",
        "test_error = 100 - test_acc * 100\n",
        "\n",
        "print(f\"Error de entrenamiento: {train_error:.2f}%\")\n",
        "print(f\"Error de prueba: {test_error:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Red neuronal convolucional (NN-3)\n",
        "\n",
        "Entrenada con gradiente descendente estocástico: 2.7% de error sobre el conjunto de prueba."
      ],
      "metadata": {
        "id": "TqjMxugFzZcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "k0O6V_VMLGsT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),  # Primera capa convolutiva\n",
        "    MaxPooling2D(pool_size=(2, 2)),                                              # Capa de max-pooling\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),                           # Segunda capa convolutiva\n",
        "    MaxPooling2D(pool_size=(2, 2)),                                              # Capa de max-pooling\n",
        "    Flatten(),                                                                   # Aplanar la salida\n",
        "    Dense(128, activation='relu'),                                               # Capa densa con 128 unidades\n",
        "    Dense(10, activation='softmax')                                              # Capa de salida softmax\n",
        "])\n",
        "\n",
        "# Compilar el modelo usando SGD\n",
        "model.compile(optimizer=SGD(learning_rate=0.01, momentum=0.9),  # SGD con momentum\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    epochs=15,            # Ajustar para garantizar buena convergencia\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2, # Validación interna\n",
        "                    verbose=2)\n",
        "\n",
        "# Calcular el tiempo de entrenamiento\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"Tiempo de entrenamiento: {training_time:.2f} segundos\")\n",
        "\n",
        "# Evaluar el modelo en el conjunto de entrenamiento completo\n",
        "train_loss, train_acc = model.evaluate(train_images, train_labels, verbose=0)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
        "\n",
        "# Calcular y mostrar los errores\n",
        "train_error = 100 - train_acc * 100\n",
        "test_error = 100 - test_acc * 100\n",
        "\n",
        "print(f\"Error de entrenamiento: {train_error:.2f}%\")\n",
        "print(f\"Error de prueba: {test_error:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLbS_LF71djC",
        "outputId": "0cd1e269-b946-4284-e107-6f5f0dbd47ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1500/1500 - 5s - 4ms/step - accuracy: 0.9362 - loss: 0.2047 - val_accuracy: 0.9790 - val_loss: 0.0717\n",
            "Epoch 2/15\n",
            "1500/1500 - 3s - 2ms/step - accuracy: 0.9809 - loss: 0.0606 - val_accuracy: 0.9730 - val_loss: 0.0849\n",
            "Epoch 3/15\n",
            "1500/1500 - 4s - 3ms/step - accuracy: 0.9869 - loss: 0.0409 - val_accuracy: 0.9849 - val_loss: 0.0500\n",
            "Epoch 4/15\n",
            "1500/1500 - 4s - 2ms/step - accuracy: 0.9902 - loss: 0.0305 - val_accuracy: 0.9882 - val_loss: 0.0436\n",
            "Epoch 5/15\n",
            "1500/1500 - 6s - 4ms/step - accuracy: 0.9920 - loss: 0.0242 - val_accuracy: 0.9881 - val_loss: 0.0452\n",
            "Epoch 6/15\n",
            "1500/1500 - 4s - 3ms/step - accuracy: 0.9942 - loss: 0.0182 - val_accuracy: 0.9878 - val_loss: 0.0418\n",
            "Epoch 7/15\n",
            "1500/1500 - 4s - 3ms/step - accuracy: 0.9958 - loss: 0.0131 - val_accuracy: 0.9877 - val_loss: 0.0447\n",
            "Epoch 8/15\n",
            "1500/1500 - 3s - 2ms/step - accuracy: 0.9963 - loss: 0.0115 - val_accuracy: 0.9887 - val_loss: 0.0433\n",
            "Epoch 9/15\n",
            "1500/1500 - 6s - 4ms/step - accuracy: 0.9973 - loss: 0.0088 - val_accuracy: 0.9902 - val_loss: 0.0391\n",
            "Epoch 10/15\n",
            "1500/1500 - 4s - 3ms/step - accuracy: 0.9980 - loss: 0.0066 - val_accuracy: 0.9890 - val_loss: 0.0501\n",
            "Epoch 11/15\n",
            "1500/1500 - 4s - 3ms/step - accuracy: 0.9984 - loss: 0.0048 - val_accuracy: 0.9887 - val_loss: 0.0470\n",
            "Epoch 12/15\n",
            "1500/1500 - 5s - 3ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9883 - val_loss: 0.0551\n",
            "Epoch 13/15\n",
            "1500/1500 - 4s - 2ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9902 - val_loss: 0.0497\n",
            "Epoch 14/15\n",
            "1500/1500 - 3s - 2ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9898 - val_loss: 0.0555\n",
            "Epoch 15/15\n",
            "1500/1500 - 7s - 5ms/step - accuracy: 0.9998 - loss: 6.8244e-04 - val_accuracy: 0.9898 - val_loss: 0.0565\n",
            "Tiempo de entrenamiento: 73.32 segundos\n",
            "Error de entrenamiento: 0.25%\n",
            "Error de prueba: 0.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep learning con autoencoders (NN-4)\n",
        "\n",
        "“Deep learning” usando pre-entrenamiento de autoencoders para extraer características de las imágenes y una red neuronal simple con una capa de salida tipo softmax."
      ],
      "metadata": {
        "id": "WHarzpKC_rZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time"
      ],
      "metadata": {
        "id": "JD3_7OOBTyLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el autoencoder\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "# Codificador\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Decodificador\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Entrenar el autoencoder\n",
        "start_time = time.time()\n",
        "autoencoder.fit(train_images, train_images,\n",
        "                epochs=10,\n",
        "                batch_size=256,\n",
        "                validation_split=0.2,\n",
        "                verbose=2)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Tiempo de entrenamiento del autoencoder: {end_time - start_time:.2f} segundos\")\n",
        "\n",
        "# Extraer características del autoencoder\n",
        "encoder = Model(input_img, encoded)\n",
        "encoded_train = encoder.predict(train_images)\n",
        "encoded_test = encoder.predict(test_images)\n",
        "\n",
        "# Aplanar las características extraídas\n",
        "X_train_flat = encoded_train.reshape(encoded_train.shape[0], -1)\n",
        "X_test_flat = encoded_test.reshape(encoded_test.shape[0], -1)\n",
        "\n",
        "# Crear y entrenar la red neuronal simple\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_flat.shape[1],)),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo usando SGD\n",
        "model.compile(optimizer=SGD(learning_rate=0.01, momentum=0.9),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo supervisado\n",
        "start_time = time.time()\n",
        "history = model.fit(X_train_flat, train_labels,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=2)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Tiempo de entrenamiento total (autoencoder + red neuronal): {end_time - start_time + (end_time - start_time):.2f} segundos\")\n",
        "\n",
        "# Evaluar el modelo\n",
        "train_loss, train_acc = model.evaluate(X_train_flat, train_labels, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(X_test_flat, test_labels, verbose=0)\n",
        "\n",
        "# Calcular errores\n",
        "train_error = 100 - train_acc * 100\n",
        "test_error = 100 - test_acc * 100\n",
        "\n",
        "print(f\"Error de entrenamiento: {train_error:.2f}%\")\n",
        "print(f\"Error de prueba: {test_error:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlAPViXk_9aY",
        "outputId": "274a601b-11c0-4add-9820-694f67d598eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 - 9s - 47ms/step - loss: 0.1437 - val_loss: 0.0833\n",
            "Epoch 2/10\n",
            "188/188 - 2s - 11ms/step - loss: 0.0784 - val_loss: 0.0764\n",
            "Epoch 3/10\n",
            "188/188 - 2s - 12ms/step - loss: 0.0741 - val_loss: 0.0734\n",
            "Epoch 4/10\n",
            "188/188 - 2s - 12ms/step - loss: 0.0721 - val_loss: 0.0718\n",
            "Epoch 5/10\n",
            "188/188 - 2s - 11ms/step - loss: 0.0708 - val_loss: 0.0707\n",
            "Epoch 6/10\n",
            "188/188 - 3s - 14ms/step - loss: 0.0698 - val_loss: 0.0705\n",
            "Epoch 7/10\n",
            "188/188 - 2s - 11ms/step - loss: 0.0690 - val_loss: 0.0692\n",
            "Epoch 8/10\n",
            "188/188 - 3s - 14ms/step - loss: 0.0685 - val_loss: 0.0687\n",
            "Epoch 9/10\n",
            "188/188 - 2s - 13ms/step - loss: 0.0680 - val_loss: 0.0682\n",
            "Epoch 10/10\n",
            "188/188 - 2s - 11ms/step - loss: 0.0675 - val_loss: 0.0677\n",
            "Tiempo de entrenamiento del autoencoder: 30.00 segundos\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 - 5s - 3ms/step - accuracy: 0.8990 - loss: 0.3169 - val_accuracy: 0.9404 - val_loss: 0.1914\n",
            "Epoch 2/20\n",
            "1500/1500 - 3s - 2ms/step - accuracy: 0.9462 - loss: 0.1712 - val_accuracy: 0.9377 - val_loss: 0.2146\n",
            "Epoch 3/20\n",
            "1500/1500 - 5s - 3ms/step - accuracy: 0.9560 - loss: 0.1385 - val_accuracy: 0.9536 - val_loss: 0.1706\n",
            "Epoch 4/20\n",
            "1500/1500 - 5s - 3ms/step - accuracy: 0.9632 - loss: 0.1185 - val_accuracy: 0.9564 - val_loss: 0.1543\n",
            "Epoch 5/20\n",
            "1500/1500 - 3s - 2ms/step - accuracy: 0.9668 - loss: 0.1049 - val_accuracy: 0.9666 - val_loss: 0.1146\n",
            "Epoch 6/20\n",
            "1500/1500 - 3s - 2ms/step - accuracy: 0.9706 - loss: 0.0948 - val_accuracy: 0.9636 - val_loss: 0.1176\n",
            "Epoch 7/20\n",
            "1500/1500 - 6s - 4ms/step - accuracy: 0.9724 - loss: 0.0871 - val_accuracy: 0.9665 - val_loss: 0.1164\n",
            "Epoch 8/20\n",
            "1500/1500 - 4s - 3ms/step - accuracy: 0.9756 - loss: 0.0785 - val_accuracy: 0.9720 - val_loss: 0.0923\n",
            "Epoch 9/20\n",
            "1500/1500 - 5s - 3ms/step - accuracy: 0.9761 - loss: 0.0757 - val_accuracy: 0.9731 - val_loss: 0.0909\n",
            "Epoch 10/20\n",
            "1500/1500 - 5s - 3ms/step - accuracy: 0.9767 - loss: 0.0741 - val_accuracy: 0.9684 - val_loss: 0.1117\n",
            "Epoch 11/20\n",
            "1500/1500 - 3s - 2ms/step - accuracy: 0.9780 - loss: 0.0697 - val_accuracy: 0.9757 - val_loss: 0.0846\n",
            "Epoch 12/20\n",
            "1500/1500 - 3s - 2ms/step - accuracy: 0.9794 - loss: 0.0629 - val_accuracy: 0.9706 - val_loss: 0.1154\n",
            "Epoch 13/20\n",
            "1500/1500 - 6s - 4ms/step - accuracy: 0.9797 - loss: 0.0632 - val_accuracy: 0.9761 - val_loss: 0.0936\n",
            "Epoch 14/20\n",
            "1500/1500 - 3s - 2ms/step - accuracy: 0.9815 - loss: 0.0568 - val_accuracy: 0.9731 - val_loss: 0.0951\n",
            "Epoch 15/20\n",
            "1500/1500 - 5s - 3ms/step - accuracy: 0.9820 - loss: 0.0567 - val_accuracy: 0.9747 - val_loss: 0.0849\n",
            "Epoch 16/20\n",
            "1500/1500 - 7s - 4ms/step - accuracy: 0.9825 - loss: 0.0519 - val_accuracy: 0.9757 - val_loss: 0.0878\n",
            "Epoch 17/20\n",
            "1500/1500 - 3s - 2ms/step - accuracy: 0.9835 - loss: 0.0501 - val_accuracy: 0.9787 - val_loss: 0.0757\n",
            "Epoch 18/20\n",
            "1500/1500 - 5s - 3ms/step - accuracy: 0.9849 - loss: 0.0488 - val_accuracy: 0.9788 - val_loss: 0.0803\n",
            "Epoch 19/20\n",
            "1500/1500 - 4s - 3ms/step - accuracy: 0.9851 - loss: 0.0460 - val_accuracy: 0.9763 - val_loss: 0.0912\n",
            "Epoch 20/20\n",
            "1500/1500 - 3s - 2ms/step - accuracy: 0.9852 - loss: 0.0439 - val_accuracy: 0.9761 - val_loss: 0.0828\n",
            "Tiempo de entrenamiento total (autoencoder + red neuronal): 173.28 segundos\n",
            "Error de entrenamiento: 1.45%\n",
            "Error de prueba: 2.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Redes neuronales combinadas\n",
        "\n",
        "Mezclando las técnicas vistas anteriormente."
      ],
      "metadata": {
        "id": "0i2JxppqBugP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mejora de la NN-3 (NN-5)\n",
        "\n"
      ],
      "metadata": {
        "id": "_YRIWEWsa_A1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "# Dividir los datos en entrenamiento y validación\n",
        "train_images_split, val_images_split, train_labels_split, val_labels_split = train_test_split(\n",
        "    train_images, train_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Generador con aumentación para datos de entrenamiento\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "\n",
        "# Generador sin aumentación para datos de validación\n",
        "val_datagen = ImageDataGenerator()\n",
        "\n",
        "# Preparar los generadores\n",
        "train_generator = train_datagen.flow(train_images_split, train_labels_split, batch_size=32)\n",
        "val_generator = val_datagen.flow(val_images_split, val_labels_split, batch_size=32)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks para optimización\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=17, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
        "    ModelCheckpoint('best_model.keras', save_best_only=True, verbose=1)\n",
        "]\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=85,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"Tiempo de entrenamiento: {training_time:.2f} segundos\")\n",
        "\n",
        "# Evaluar el modelo\n",
        "train_loss, train_acc = model.evaluate(train_images, train_labels, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
        "\n",
        "# Calcular y mostrar los errores\n",
        "train_error = 100 - train_acc * 100\n",
        "test_error = 100 - test_acc * 100\n",
        "\n",
        "print(f\"Entrenamiento. Accuracy: {train_acc * 100:.2f}% - Error: {train_error:.2f}%\")\n",
        "print(f\"Prueba. Accuracy: {test_acc * 100:.2f}% - Error: {test_error:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QZRhQRhnLoV",
        "outputId": "af324634-1537-4478-cff0-7eee68d7a1cc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/85\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.05263, saving model to best_model.keras\n",
            "1500/1500 - 24s - 16ms/step - accuracy: 0.8808 - loss: 0.3786 - val_accuracy: 0.9845 - val_loss: 0.0526 - learning_rate: 0.0010\n",
            "Epoch 2/85\n",
            "\n",
            "Epoch 2: val_loss improved from 0.05263 to 0.04382, saving model to best_model.keras\n",
            "1500/1500 - 43s - 29ms/step - accuracy: 0.9538 - loss: 0.1512 - val_accuracy: 0.9869 - val_loss: 0.0438 - learning_rate: 0.0010\n",
            "Epoch 3/85\n",
            "\n",
            "Epoch 3: val_loss improved from 0.04382 to 0.03315, saving model to best_model.keras\n",
            "1500/1500 - 38s - 25ms/step - accuracy: 0.9622 - loss: 0.1238 - val_accuracy: 0.9896 - val_loss: 0.0332 - learning_rate: 0.0010\n",
            "Epoch 4/85\n",
            "\n",
            "Epoch 4: val_loss improved from 0.03315 to 0.03084, saving model to best_model.keras\n",
            "1500/1500 - 42s - 28ms/step - accuracy: 0.9683 - loss: 0.1069 - val_accuracy: 0.9904 - val_loss: 0.0308 - learning_rate: 0.0010\n",
            "Epoch 5/85\n",
            "\n",
            "Epoch 5: val_loss improved from 0.03084 to 0.02966, saving model to best_model.keras\n",
            "1500/1500 - 44s - 29ms/step - accuracy: 0.9711 - loss: 0.0961 - val_accuracy: 0.9912 - val_loss: 0.0297 - learning_rate: 0.0010\n",
            "Epoch 6/85\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.02966\n",
            "1500/1500 - 36s - 24ms/step - accuracy: 0.9740 - loss: 0.0869 - val_accuracy: 0.9901 - val_loss: 0.0317 - learning_rate: 0.0010\n",
            "Epoch 7/85\n",
            "\n",
            "Epoch 7: val_loss improved from 0.02966 to 0.02529, saving model to best_model.keras\n",
            "1500/1500 - 22s - 14ms/step - accuracy: 0.9748 - loss: 0.0828 - val_accuracy: 0.9920 - val_loss: 0.0253 - learning_rate: 0.0010\n",
            "Epoch 8/85\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.02529\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9766 - loss: 0.0766 - val_accuracy: 0.9919 - val_loss: 0.0274 - learning_rate: 0.0010\n",
            "Epoch 9/85\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.02529\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9776 - loss: 0.0761 - val_accuracy: 0.9902 - val_loss: 0.0337 - learning_rate: 0.0010\n",
            "Epoch 10/85\n",
            "\n",
            "Epoch 10: val_loss improved from 0.02529 to 0.02368, saving model to best_model.keras\n",
            "1500/1500 - 41s - 27ms/step - accuracy: 0.9794 - loss: 0.0693 - val_accuracy: 0.9926 - val_loss: 0.0237 - learning_rate: 0.0010\n",
            "Epoch 11/85\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.02368\n",
            "1500/1500 - 41s - 28ms/step - accuracy: 0.9796 - loss: 0.0706 - val_accuracy: 0.9928 - val_loss: 0.0239 - learning_rate: 0.0010\n",
            "Epoch 12/85\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.02368\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9808 - loss: 0.0664 - val_accuracy: 0.9925 - val_loss: 0.0272 - learning_rate: 0.0010\n",
            "Epoch 13/85\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.02368\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9809 - loss: 0.0632 - val_accuracy: 0.9926 - val_loss: 0.0274 - learning_rate: 0.0010\n",
            "Epoch 14/85\n",
            "\n",
            "Epoch 14: val_loss improved from 0.02368 to 0.02195, saving model to best_model.keras\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9835 - loss: 0.0546 - val_accuracy: 0.9937 - val_loss: 0.0220 - learning_rate: 5.0000e-04\n",
            "Epoch 15/85\n",
            "\n",
            "Epoch 15: val_loss improved from 0.02195 to 0.02163, saving model to best_model.keras\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9858 - loss: 0.0476 - val_accuracy: 0.9933 - val_loss: 0.0216 - learning_rate: 5.0000e-04\n",
            "Epoch 16/85\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.02163\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9856 - loss: 0.0508 - val_accuracy: 0.9934 - val_loss: 0.0235 - learning_rate: 5.0000e-04\n",
            "Epoch 17/85\n",
            "\n",
            "Epoch 17: val_loss improved from 0.02163 to 0.01928, saving model to best_model.keras\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9858 - loss: 0.0477 - val_accuracy: 0.9941 - val_loss: 0.0193 - learning_rate: 5.0000e-04\n",
            "Epoch 18/85\n",
            "\n",
            "Epoch 18: val_loss improved from 0.01928 to 0.01873, saving model to best_model.keras\n",
            "1500/1500 - 22s - 15ms/step - accuracy: 0.9864 - loss: 0.0464 - val_accuracy: 0.9951 - val_loss: 0.0187 - learning_rate: 5.0000e-04\n",
            "Epoch 19/85\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.01873\n",
            "1500/1500 - 19s - 12ms/step - accuracy: 0.9870 - loss: 0.0429 - val_accuracy: 0.9942 - val_loss: 0.0209 - learning_rate: 5.0000e-04\n",
            "Epoch 20/85\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.01873\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9864 - loss: 0.0453 - val_accuracy: 0.9939 - val_loss: 0.0212 - learning_rate: 5.0000e-04\n",
            "Epoch 21/85\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.01873\n",
            "1500/1500 - 22s - 15ms/step - accuracy: 0.9868 - loss: 0.0454 - val_accuracy: 0.9941 - val_loss: 0.0195 - learning_rate: 5.0000e-04\n",
            "Epoch 22/85\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.01873\n",
            "1500/1500 - 39s - 26ms/step - accuracy: 0.9889 - loss: 0.0378 - val_accuracy: 0.9944 - val_loss: 0.0190 - learning_rate: 2.5000e-04\n",
            "Epoch 23/85\n",
            "\n",
            "Epoch 23: val_loss improved from 0.01873 to 0.01770, saving model to best_model.keras\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9891 - loss: 0.0387 - val_accuracy: 0.9949 - val_loss: 0.0177 - learning_rate: 2.5000e-04\n",
            "Epoch 24/85\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.01770\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9887 - loss: 0.0380 - val_accuracy: 0.9941 - val_loss: 0.0189 - learning_rate: 2.5000e-04\n",
            "Epoch 25/85\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.01770\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9890 - loss: 0.0386 - val_accuracy: 0.9951 - val_loss: 0.0177 - learning_rate: 2.5000e-04\n",
            "Epoch 26/85\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.01770\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9896 - loss: 0.0358 - val_accuracy: 0.9948 - val_loss: 0.0193 - learning_rate: 2.5000e-04\n",
            "Epoch 27/85\n",
            "\n",
            "Epoch 27: val_loss improved from 0.01770 to 0.01759, saving model to best_model.keras\n",
            "1500/1500 - 41s - 27ms/step - accuracy: 0.9904 - loss: 0.0328 - val_accuracy: 0.9947 - val_loss: 0.0176 - learning_rate: 1.2500e-04\n",
            "Epoch 28/85\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.01759\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9903 - loss: 0.0341 - val_accuracy: 0.9951 - val_loss: 0.0178 - learning_rate: 1.2500e-04\n",
            "Epoch 29/85\n",
            "\n",
            "Epoch 29: val_loss improved from 0.01759 to 0.01742, saving model to best_model.keras\n",
            "1500/1500 - 22s - 14ms/step - accuracy: 0.9903 - loss: 0.0322 - val_accuracy: 0.9947 - val_loss: 0.0174 - learning_rate: 1.2500e-04\n",
            "Epoch 30/85\n",
            "\n",
            "Epoch 30: val_loss improved from 0.01742 to 0.01726, saving model to best_model.keras\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9903 - loss: 0.0330 - val_accuracy: 0.9955 - val_loss: 0.0173 - learning_rate: 1.2500e-04\n",
            "Epoch 31/85\n",
            "\n",
            "Epoch 31: val_loss improved from 0.01726 to 0.01648, saving model to best_model.keras\n",
            "1500/1500 - 39s - 26ms/step - accuracy: 0.9910 - loss: 0.0321 - val_accuracy: 0.9951 - val_loss: 0.0165 - learning_rate: 1.2500e-04\n",
            "Epoch 32/85\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.01648\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9907 - loss: 0.0306 - val_accuracy: 0.9950 - val_loss: 0.0169 - learning_rate: 1.2500e-04\n",
            "Epoch 33/85\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.01648\n",
            "1500/1500 - 20s - 14ms/step - accuracy: 0.9910 - loss: 0.0312 - val_accuracy: 0.9950 - val_loss: 0.0169 - learning_rate: 1.2500e-04\n",
            "Epoch 34/85\n",
            "\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.01648\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9910 - loss: 0.0304 - val_accuracy: 0.9951 - val_loss: 0.0173 - learning_rate: 1.2500e-04\n",
            "Epoch 35/85\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.01648\n",
            "1500/1500 - 22s - 14ms/step - accuracy: 0.9915 - loss: 0.0292 - val_accuracy: 0.9956 - val_loss: 0.0168 - learning_rate: 6.2500e-05\n",
            "Epoch 36/85\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.01648\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9905 - loss: 0.0321 - val_accuracy: 0.9953 - val_loss: 0.0167 - learning_rate: 6.2500e-05\n",
            "Epoch 37/85\n",
            "\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 37: val_loss improved from 0.01648 to 0.01644, saving model to best_model.keras\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9911 - loss: 0.0311 - val_accuracy: 0.9957 - val_loss: 0.0164 - learning_rate: 6.2500e-05\n",
            "Epoch 38/85\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.01644\n",
            "1500/1500 - 20s - 14ms/step - accuracy: 0.9912 - loss: 0.0273 - val_accuracy: 0.9954 - val_loss: 0.0169 - learning_rate: 3.1250e-05\n",
            "Epoch 39/85\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.01644\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9910 - loss: 0.0299 - val_accuracy: 0.9953 - val_loss: 0.0173 - learning_rate: 3.1250e-05\n",
            "Epoch 40/85\n",
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.01644\n",
            "1500/1500 - 22s - 15ms/step - accuracy: 0.9925 - loss: 0.0267 - val_accuracy: 0.9952 - val_loss: 0.0166 - learning_rate: 3.1250e-05\n",
            "Epoch 41/85\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.01644\n",
            "1500/1500 - 38s - 25ms/step - accuracy: 0.9914 - loss: 0.0283 - val_accuracy: 0.9952 - val_loss: 0.0167 - learning_rate: 1.5625e-05\n",
            "Epoch 42/85\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.01644\n",
            "1500/1500 - 20s - 14ms/step - accuracy: 0.9920 - loss: 0.0269 - val_accuracy: 0.9953 - val_loss: 0.0168 - learning_rate: 1.5625e-05\n",
            "Epoch 43/85\n",
            "\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.01644\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9915 - loss: 0.0287 - val_accuracy: 0.9953 - val_loss: 0.0167 - learning_rate: 1.5625e-05\n",
            "Epoch 44/85\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.01644\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9916 - loss: 0.0279 - val_accuracy: 0.9952 - val_loss: 0.0168 - learning_rate: 7.8125e-06\n",
            "Epoch 45/85\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.01644\n",
            "1500/1500 - 19s - 12ms/step - accuracy: 0.9917 - loss: 0.0284 - val_accuracy: 0.9952 - val_loss: 0.0168 - learning_rate: 7.8125e-06\n",
            "Epoch 46/85\n",
            "\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.01644\n",
            "1500/1500 - 22s - 15ms/step - accuracy: 0.9916 - loss: 0.0269 - val_accuracy: 0.9953 - val_loss: 0.0168 - learning_rate: 7.8125e-06\n",
            "Epoch 47/85\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.01644\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9921 - loss: 0.0270 - val_accuracy: 0.9953 - val_loss: 0.0168 - learning_rate: 3.9063e-06\n",
            "Epoch 48/85\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.01644\n",
            "1500/1500 - 20s - 14ms/step - accuracy: 0.9920 - loss: 0.0276 - val_accuracy: 0.9953 - val_loss: 0.0168 - learning_rate: 3.9063e-06\n",
            "Epoch 49/85\n",
            "\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.01644\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9914 - loss: 0.0282 - val_accuracy: 0.9953 - val_loss: 0.0169 - learning_rate: 3.9063e-06\n",
            "Epoch 50/85\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.01644\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9918 - loss: 0.0290 - val_accuracy: 0.9953 - val_loss: 0.0169 - learning_rate: 1.9531e-06\n",
            "Epoch 51/85\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.01644\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9919 - loss: 0.0273 - val_accuracy: 0.9953 - val_loss: 0.0169 - learning_rate: 1.9531e-06\n",
            "Epoch 52/85\n",
            "\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.01644\n",
            "1500/1500 - 19s - 12ms/step - accuracy: 0.9923 - loss: 0.0261 - val_accuracy: 0.9955 - val_loss: 0.0168 - learning_rate: 1.9531e-06\n",
            "Epoch 53/85\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.01644\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9924 - loss: 0.0272 - val_accuracy: 0.9955 - val_loss: 0.0168 - learning_rate: 1.0000e-06\n",
            "Epoch 54/85\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.01644\n",
            "1500/1500 - 20s - 14ms/step - accuracy: 0.9906 - loss: 0.0298 - val_accuracy: 0.9955 - val_loss: 0.0168 - learning_rate: 1.0000e-06\n",
            "Epoch 54: early stopping\n",
            "Restoring model weights from the end of the best epoch: 37.\n",
            "Tiempo de entrenamiento: 1310.51 segundos\n",
            "Entrenamiento. Accuracy: 99.76% - Error: 0.24%\n",
            "Prueba. Accuracy: 99.62% - Error: 0.38%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener predicciones para el conjunto de prueba\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Transformar las predicciones a etiquetas (la clase con mayor probabilidad)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Imprimir 10000 dígitos y todos seguidos\n",
        "print(''.join(map(str, predicted_labels)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdfifHssoIrq",
        "outputId": "8f06b27a-a03a-4977-eee7-6e499f413487"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "7210414959069015973496654074013134727121174235124463556041957893746430702917329776278473613693141769605499219487397444925476790585665781016467317182029955156034465465451447232718181850892501110903164236111395294593903655722712841733887922415987230442419577282685779181803019941821297592641582920400284712402743300319652592930420711215339786561381051315561851744622506563720885411403376162192861952544283824503177579719214292049148184598837600302064933323912680566638827589618412591975408991052378940639521313657422632654897130383193446421825488400232770874479690980460635483393337808217065438096380996868578602402231975108462479329822927359180205213767125803724091867743491951739769137833672858511443107707944855408210845040617326726931462542062173410543117499484024511647194241553831456894153803251283440883317359632613607217142421796112481774807313107703552766928352256082928888749306632132293005781446029147473988471212232323917403558632676632791175649513347891169144540622315120381267162390122089902519781041795426813754418138125806211115346950922482172494403922338357358124464951069595973803713678597969637445354787807688733195273511214747545408369602744446647934558737270241166928720150917060868180337236216113790805402872984095851213174572098862541921587024436882405044793415973588053366016035441291469939844313188794887971456052221552496277221128372417176782731758262256509243397668041382918067210552022024980994654918349912281964094838602519629409606354238455038535865763396112904336957377787983072794549321402375788501148390006623784779241452499184098487707886048824766647188236300376979954336123733203384363502090746935196145450595212919940845292121736884919857511865244323568862310589296704871741097200917878472046031133967415308739693502745175808815030314037271807043198771499321790203376923377007529874426619682908311635111312302013557489696836685142445119024957183569871167632208925108145796906155838265074613473234252717264157860182577693584240883492758656086736494663241014629110639565658464391341917179354073617553301575865104234679818492862700675860937135433556302342309947284706285285730823282557646848274520399672561123678764894863831062256958141784618431280859342027090257679426244804458068985690487134580913369871057175279185249472234919217944167278819711753351376138759400288237130344389239711704965917020046707146454991795338236221111169843716450474240701988600496822384822175440439731012542101891683893628322104292437915249038536094625007466866869172599072767065247209922944233217076413874592518737155091406336049751689557938381535055386777370590255317786593895379170037238186295757862514845830627332107340393289038076547390862511004401232778525769141642435439501538919795527460111044763004306196138125627360197668929583100766216931869060006359345585304029682312115698066553862145437850935110447017016145665784472537077964285783958998628923611893407964141349314774729308884044152834952815379425635935931953069840452901031658153303559287049197755209186239621913550383376601406981299597378013046102584411540606926271794003822316057792679786884684128239403732337340620815354171575732273737854525653674171523631426743806216539193218446586977869739405464123002665708647907342188592718882760127108360536287014211444471629900188434206161222123781002166016251748214383994834727570433267600677055810702815088032772647555292846865008761711274007763864209405782747113662919483695962467706694835349005250711107679664143112241087634006330717113109975414895351982339901029393362498374047849899759282202238468682467933943144705960444461233645968565864186528455477078223701807198755917549122166711407424064769534650188283578085711013785071101145276230285969721364182405102264439616579202601435288088909676393477749064842728100783331376131665747595849918501370348220251514889121351094483259766200058215238518204996233564809283675729491286070911675991959250410890898942579898099689959851033521650281562302264355172169199551622867146040332236898538545205632839957946713736609019928801697534749943631176918411994368160413774951001162198403649071657525185470670258104571851900607318397008959832729721137531982228857389886823975629288168879180172075190209862393802111142977511219991020211464154977756222806961977148534349750748815395976903639822128685539492515144144359122330290099609328419972799595118351953549593190975492010514933615252209266012030255795508950325908845884548549221268870366438872200939919866426928545799921834078393465623926006128798204775056467430750742089942467876941373088769392292183296840128452781130357031936317730848265297390996429721167475968214457613259936114697215146381103168490730290666367728608302983253880019513960141712379749939282718091017796999216135719764576699636298122552372101045282835178112978405078847785849813803178551657493547120816073473960864877938697234021835572467283087890844585663093768934958912886813790114708174571211396212807669370528054384662795132436194476541992780136134111560707232522949812161278000822922799275134941856283128499370772324039984106096861198923559421943960406012347890123478901234567898347863409719384730914546206211117247529458429700751176668227740242189610596980308396301234567012345678901234567854874773988315827421545586444187551891363322699655338165681976837470900379302010104010479626229901234567890123456789012345678980566080237947191714004175713331697430252608943548159064363381475722001779598968823612989526248465015678901234567890123456789742090158802784461045394205013291601180477636073542418356706712581938287671462930123456701234501289140950807711293672381298871711034264742749106855535974859693038918160012345678901234567890123456789353293214552321397212891887810027875061574612507990384481865900037164266045413863995937856476220940123456789012356012345687132807599609413212383265682748180539419219679046173872965839057161093344062542346002014567890123456780123456789871375280759909115886321832656741053192196046173872965835716109625423446002012343678901234567890128456789865068941953048914055215407601706899179860817713231420078464938472563696322469025513397872257982131301234567890123456789012345678912653070414367231212960130275762919060602061584301544857578348852971381075969477993443862012345678901234567890123456789083955268491712359691112956812077582989046713456036870427475434281512025643000335706488634699827710123456789012345678012345678217250802788360276612887747737454338411974373302556635259984106096885611989235594219392060400123478901237890123478973031876402683281207104458062315185940758838926253173919960392814352925895012456012345671234510456634428106497233920933915237784024024780706932867575108167297958626281750113249186890123456789012347890178998984177337666190176321713917684143696144724401234567890123456901234781351772148344397412359160100287114047368037406926586904061920951376930220123456789012345678901234567892172508027883060276612887747737454338454119743733025563152599841060968856119892355942194913920604060123456789012345678901234567893807107556901008343150095349376924572649494122581329438221286516721393875707488506637699484106601234567890123456789012345678974040179514289437824433699586706826393286174889033905294103758778297126425236650028161043161901456789123456701234567898400724386632633014780319019127013829276559982913234319093687010582770123456789012345678901234567891748156572863386540917291513223064376904814061269223551077962947023400888513749889098902656747541353123456123460124567817241414968453784335670616870150850158423976919067123924553753182230294970274992598386700123456789012345678901234567890072655378666643883019054191270138292742655991157682943190936870105827701234567890123458901234567892121399853707757994703415814841866460553357259692621208383087495097004609162768352183861021401234567890123456789012345678976476234878698322848565020112968210652975393718381955011982604503186759930314404901235678012356789012356789970901588093278461049420501693291601187763607241706712581828768716293012345678901234567890123456789895703168415642781343472050192323557849971190783486380962101062389072345528546667918215347940001234567890123456789012345690131512492468011926687429702103601234567890123456789012345678986597023438515230121326530727464059989531747654006620637744392896095388714048523901915174862168801234789012346789012347891453309543084670771691362382389588717110342647427429279210653485969063081600123456701234789012347251643990971643620986570017432413764777984382835805471317962091733916439821864155650123456789012345678901234567896970234385130121320726405998953174700666374289871404852390191517612168012345678901234567801235678104566344281064972920933915231673784024024780706932486057510816729795652628175573501138494518689012345678901234567890123456789353293214552321397212891887810067787506157461250799034484186590003716460454138639959378564762209401234567890123456789012345678964264755472939382095601065353800341530830627817138542097674162671980694996237192253780123478901234789017898926135482643459203949738744985826623132731901135078151460049166907611012347234567012786397193961724457001668277242161069839630123456789012345678901234567891689901244374440387582175385251162138642625502806817919267668749213305580379702791780353601234567890123456789012347896426478929393001042635303415308306178092671969499671253780124567890134567801347897551997100597172236832006175862948871087758534611550723641241542048619025693636012345678901234567890123567810957518690419384470192878259606553339811061006211327788784602070368715993724943622532559417201234567890123456789012345678910127534400696657234491407957231440996183373988477621987887223933550795651411282615012345678901234567890123456788060023794719171400175713331697130260894354815906138147520017876882361295201234567890123456789012346678974614099378475853220586038103047492957171665628764995374304661132100123478901234567801234789083955268417123569111212077582986734687042775434281510233570686399827710178901834567801234789786419384470192878260653339140610062117784607036871524943641726501234567890123456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combo NN-4+5 (NN-6)"
      ],
      "metadata": {
        "id": "0zPXilaSj6ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "# Crear el autoencoder\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "start_time = time.time()\n",
        "autoencoder.fit(train_images, train_images,\n",
        "                epochs=10,\n",
        "                batch_size=256,\n",
        "                validation_split=0.2,\n",
        "                verbose=2)\n",
        "end_time = time.time()\n",
        "print(f\"Tiempo de entrenamiento del autoencoder: {end_time - start_time:.2f} segundos\")\n",
        "\n",
        "encoder = Model(input_img, encoded)\n",
        "encoded_train = encoder.predict(train_images)\n",
        "encoded_test = encoder.predict(test_images)\n",
        "\n",
        "train_images_split, val_images_split, train_labels_split, val_labels_split = train_test_split(\n",
        "    encoded_train, train_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "val_datagen = ImageDataGenerator()\n",
        "\n",
        "train_generator = train_datagen.flow(train_images_split, train_labels_split, batch_size=32)\n",
        "val_generator = val_datagen.flow(val_images_split, val_labels_split, batch_size=32)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(7, 7, 64), padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=7, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
        "    ModelCheckpoint('best_model.keras', save_best_only=True, verbose=1)\n",
        "]\n",
        "\n",
        "start_time = time.time()\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"Tiempo de entrenamiento total (autoencoder + red convolucional): {training_time:.2f} segundos\")\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "test_generator = test_datagen.flow(encoded_test, test_labels, batch_size=32, shuffle=False)\n",
        "\n",
        "train_loss, train_acc = model.evaluate(train_generator, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(test_generator, verbose=0)\n",
        "\n",
        "# Calcular y mostrar los errores\n",
        "train_error = 100 - train_acc * 100\n",
        "test_error = 100 - test_acc * 100\n",
        "\n",
        "print(f\"Entrenamiento. Accuracy: {train_acc * 100:.2f}% - Error: {train_error:.2f}%\")\n",
        "print(f\"Prueba. Accuracy: {test_acc * 100:.2f}% - Error: {test_error:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZoU5xZCj8O0",
        "outputId": "58b446e2-2084-4f04-9638-2d209a8c361e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 - 7s - 39ms/step - loss: 0.1499 - val_loss: 0.0845\n",
            "Epoch 2/10\n",
            "188/188 - 2s - 11ms/step - loss: 0.0786 - val_loss: 0.0758\n",
            "Epoch 3/10\n",
            "188/188 - 2s - 13ms/step - loss: 0.0738 - val_loss: 0.0735\n",
            "Epoch 4/10\n",
            "188/188 - 3s - 14ms/step - loss: 0.0718 - val_loss: 0.0715\n",
            "Epoch 5/10\n",
            "188/188 - 2s - 11ms/step - loss: 0.0706 - val_loss: 0.0708\n",
            "Epoch 6/10\n",
            "188/188 - 2s - 10ms/step - loss: 0.0696 - val_loss: 0.0698\n",
            "Epoch 7/10\n",
            "188/188 - 3s - 13ms/step - loss: 0.0690 - val_loss: 0.0692\n",
            "Epoch 8/10\n",
            "188/188 - 3s - 14ms/step - loss: 0.0684 - val_loss: 0.0686\n",
            "Epoch 9/10\n",
            "188/188 - 2s - 11ms/step - loss: 0.0680 - val_loss: 0.0682\n",
            "Epoch 10/10\n",
            "188/188 - 2s - 10ms/step - loss: 0.0676 - val_loss: 0.0679\n",
            "Tiempo de entrenamiento del autoencoder: 28.70 segundos\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.16215, saving model to best_model.keras\n",
            "1500/1500 - 182s - 121ms/step - accuracy: 0.7665 - loss: 0.6923 - val_accuracy: 0.9442 - val_loss: 0.1622 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 2: val_loss improved from 0.16215 to 0.10864, saving model to best_model.keras\n",
            "1500/1500 - 179s - 120ms/step - accuracy: 0.9023 - loss: 0.3051 - val_accuracy: 0.9661 - val_loss: 0.1086 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 3: val_loss improved from 0.10864 to 0.09493, saving model to best_model.keras\n",
            "1500/1500 - 202s - 134ms/step - accuracy: 0.9215 - loss: 0.2514 - val_accuracy: 0.9712 - val_loss: 0.0949 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.09493\n",
            "1500/1500 - 178s - 119ms/step - accuracy: 0.9297 - loss: 0.2255 - val_accuracy: 0.9620 - val_loss: 0.1192 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: val_loss improved from 0.09493 to 0.07957, saving model to best_model.keras\n",
            "1500/1500 - 182s - 121ms/step - accuracy: 0.9346 - loss: 0.2100 - val_accuracy: 0.9768 - val_loss: 0.0796 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.07957\n",
            "1500/1500 - 178s - 118ms/step - accuracy: 0.9387 - loss: 0.2019 - val_accuracy: 0.9715 - val_loss: 0.0927 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: val_loss improved from 0.07957 to 0.07150, saving model to best_model.keras\n",
            "1500/1500 - 204s - 136ms/step - accuracy: 0.9404 - loss: 0.1919 - val_accuracy: 0.9783 - val_loss: 0.0715 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.07150\n",
            "1500/1500 - 201s - 134ms/step - accuracy: 0.9430 - loss: 0.1872 - val_accuracy: 0.9735 - val_loss: 0.0887 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.07150\n",
            "1500/1500 - 205s - 137ms/step - accuracy: 0.9460 - loss: 0.1808 - val_accuracy: 0.9763 - val_loss: 0.0747 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 10: val_loss improved from 0.07150 to 0.06660, saving model to best_model.keras\n",
            "1500/1500 - 181s - 121ms/step - accuracy: 0.9469 - loss: 0.1774 - val_accuracy: 0.9797 - val_loss: 0.0666 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.06660\n",
            "1500/1500 - 181s - 120ms/step - accuracy: 0.9480 - loss: 0.1731 - val_accuracy: 0.9790 - val_loss: 0.0716 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.06660\n",
            "1500/1500 - 180s - 120ms/step - accuracy: 0.9482 - loss: 0.1726 - val_accuracy: 0.9787 - val_loss: 0.0721 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.06660\n",
            "1500/1500 - 202s - 134ms/step - accuracy: 0.9505 - loss: 0.1633 - val_accuracy: 0.9792 - val_loss: 0.0690 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 14: val_loss improved from 0.06660 to 0.05652, saving model to best_model.keras\n",
            "1500/1500 - 180s - 120ms/step - accuracy: 0.9613 - loss: 0.1288 - val_accuracy: 0.9821 - val_loss: 0.0565 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 15: val_loss improved from 0.05652 to 0.05583, saving model to best_model.keras\n",
            "1500/1500 - 201s - 134ms/step - accuracy: 0.9630 - loss: 0.1206 - val_accuracy: 0.9830 - val_loss: 0.0558 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 16: val_loss improved from 0.05583 to 0.05328, saving model to best_model.keras\n",
            "1500/1500 - 200s - 134ms/step - accuracy: 0.9626 - loss: 0.1240 - val_accuracy: 0.9842 - val_loss: 0.0533 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 17: val_loss improved from 0.05328 to 0.05151, saving model to best_model.keras\n",
            "1500/1500 - 178s - 119ms/step - accuracy: 0.9647 - loss: 0.1124 - val_accuracy: 0.9852 - val_loss: 0.0515 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.05151\n",
            "1500/1500 - 178s - 119ms/step - accuracy: 0.9640 - loss: 0.1199 - val_accuracy: 0.9829 - val_loss: 0.0554 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 19: val_loss improved from 0.05151 to 0.04909, saving model to best_model.keras\n",
            "1500/1500 - 201s - 134ms/step - accuracy: 0.9648 - loss: 0.1156 - val_accuracy: 0.9852 - val_loss: 0.0491 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.04909\n",
            "1500/1500 - 177s - 118ms/step - accuracy: 0.9660 - loss: 0.1119 - val_accuracy: 0.9827 - val_loss: 0.0574 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 21: val_loss improved from 0.04909 to 0.04704, saving model to best_model.keras\n",
            "1500/1500 - 178s - 119ms/step - accuracy: 0.9666 - loss: 0.1112 - val_accuracy: 0.9852 - val_loss: 0.0470 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 22: val_loss improved from 0.04704 to 0.04486, saving model to best_model.keras\n",
            "1500/1500 - 178s - 118ms/step - accuracy: 0.9660 - loss: 0.1109 - val_accuracy: 0.9873 - val_loss: 0.0449 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.04486\n",
            "1500/1500 - 178s - 119ms/step - accuracy: 0.9669 - loss: 0.1069 - val_accuracy: 0.9863 - val_loss: 0.0498 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.04486\n",
            "1500/1500 - 178s - 118ms/step - accuracy: 0.9682 - loss: 0.1046 - val_accuracy: 0.9867 - val_loss: 0.0466 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.04486\n",
            "1500/1500 - 178s - 119ms/step - accuracy: 0.9678 - loss: 0.1055 - val_accuracy: 0.9843 - val_loss: 0.0503 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 26: val_loss improved from 0.04486 to 0.04321, saving model to best_model.keras\n",
            "1500/1500 - 178s - 119ms/step - accuracy: 0.9735 - loss: 0.0867 - val_accuracy: 0.9880 - val_loss: 0.0432 - learning_rate: 2.5000e-04\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.04321\n",
            "1500/1500 - 202s - 135ms/step - accuracy: 0.9737 - loss: 0.0863 - val_accuracy: 0.9881 - val_loss: 0.0437 - learning_rate: 2.5000e-04\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 28: val_loss improved from 0.04321 to 0.04311, saving model to best_model.keras\n",
            "1500/1500 - 202s - 135ms/step - accuracy: 0.9739 - loss: 0.0853 - val_accuracy: 0.9872 - val_loss: 0.0431 - learning_rate: 2.5000e-04\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 29: val_loss improved from 0.04311 to 0.03817, saving model to best_model.keras\n",
            "1500/1500 - 210s - 140ms/step - accuracy: 0.9745 - loss: 0.0838 - val_accuracy: 0.9895 - val_loss: 0.0382 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.03817\n",
            "1500/1500 - 196s - 131ms/step - accuracy: 0.9732 - loss: 0.0849 - val_accuracy: 0.9878 - val_loss: 0.0409 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.03817\n",
            "1500/1500 - 179s - 119ms/step - accuracy: 0.9744 - loss: 0.0825 - val_accuracy: 0.9886 - val_loss: 0.0410 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.03817\n",
            "1500/1500 - 179s - 120ms/step - accuracy: 0.9755 - loss: 0.0811 - val_accuracy: 0.9879 - val_loss: 0.0396 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.03817\n",
            "1500/1500 - 179s - 119ms/step - accuracy: 0.9769 - loss: 0.0718 - val_accuracy: 0.9881 - val_loss: 0.0393 - learning_rate: 1.2500e-04\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.03817\n",
            "1500/1500 - 179s - 120ms/step - accuracy: 0.9779 - loss: 0.0710 - val_accuracy: 0.9877 - val_loss: 0.0382 - learning_rate: 1.2500e-04\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.03817\n",
            "1500/1500 - 202s - 135ms/step - accuracy: 0.9784 - loss: 0.0711 - val_accuracy: 0.9875 - val_loss: 0.0408 - learning_rate: 1.2500e-04\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 36: val_loss improved from 0.03817 to 0.03687, saving model to best_model.keras\n",
            "1500/1500 - 202s - 135ms/step - accuracy: 0.9785 - loss: 0.0709 - val_accuracy: 0.9883 - val_loss: 0.0369 - learning_rate: 6.2500e-05\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.03687\n",
            "1500/1500 - 179s - 120ms/step - accuracy: 0.9801 - loss: 0.0663 - val_accuracy: 0.9885 - val_loss: 0.0373 - learning_rate: 6.2500e-05\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.03687\n",
            "1500/1500 - 179s - 119ms/step - accuracy: 0.9786 - loss: 0.0683 - val_accuracy: 0.9884 - val_loss: 0.0373 - learning_rate: 6.2500e-05\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 39: val_loss improved from 0.03687 to 0.03561, saving model to best_model.keras\n",
            "1500/1500 - 200s - 133ms/step - accuracy: 0.9797 - loss: 0.0658 - val_accuracy: 0.9889 - val_loss: 0.0356 - learning_rate: 6.2500e-05\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.03561\n",
            "1500/1500 - 203s - 135ms/step - accuracy: 0.9792 - loss: 0.0673 - val_accuracy: 0.9887 - val_loss: 0.0367 - learning_rate: 6.2500e-05\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.03561\n",
            "1500/1500 - 178s - 119ms/step - accuracy: 0.9787 - loss: 0.0664 - val_accuracy: 0.9886 - val_loss: 0.0373 - learning_rate: 6.2500e-05\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.03561\n",
            "1500/1500 - 179s - 119ms/step - accuracy: 0.9798 - loss: 0.0644 - val_accuracy: 0.9887 - val_loss: 0.0367 - learning_rate: 6.2500e-05\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.03561\n",
            "1500/1500 - 177s - 118ms/step - accuracy: 0.9798 - loss: 0.0635 - val_accuracy: 0.9889 - val_loss: 0.0363 - learning_rate: 3.1250e-05\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.03561\n",
            "1500/1500 - 178s - 119ms/step - accuracy: 0.9805 - loss: 0.0618 - val_accuracy: 0.9890 - val_loss: 0.0361 - learning_rate: 3.1250e-05\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.03561\n",
            "1500/1500 - 200s - 133ms/step - accuracy: 0.9804 - loss: 0.0628 - val_accuracy: 0.9894 - val_loss: 0.0363 - learning_rate: 3.1250e-05\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.03561\n",
            "1500/1500 - 177s - 118ms/step - accuracy: 0.9811 - loss: 0.0624 - val_accuracy: 0.9890 - val_loss: 0.0360 - learning_rate: 1.5625e-05\n",
            "Epoch 46: early stopping\n",
            "Restoring model weights from the end of the best epoch: 39.\n",
            "Tiempo de entrenamiento total (autoencoder + red convolucional): 8621.43 segundos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (10000, 7, 7, 64) (64 channels).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenamiento. Accuracy: 98.98% - Error: 1.02%\n",
            "Prueba. Accuracy: 98.96% - Error: 1.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mejora de la NN-5 (NN-7)"
      ],
      "metadata": {
        "id": "V39bPozhROtZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Código con más épocas e imprimiendo la cadena de 10000 etiquetas**"
      ],
      "metadata": {
        "id": "FUeXdOdjr8nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir los datos en entrenamiento y validación\n",
        "train_images_split, val_images_split, train_labels_split, val_labels_split = train_test_split(\n",
        "    train_images, train_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Generador con aumentación para datos de entrenamiento\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "\n",
        "# Generador sin aumentación para datos de validación\n",
        "val_datagen = ImageDataGenerator()\n",
        "\n",
        "# Preparar los generadores\n",
        "train_generator = train_datagen.flow(train_images_split, train_labels_split, batch_size=32)\n",
        "val_generator = val_datagen.flow(val_images_split, val_labels_split, batch_size=32)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    GlobalAveragePooling2D(),\n",
        "\n",
        "    Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    Dropout(0.4),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks para optimización\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
        "    ModelCheckpoint('best_model.keras', save_best_only=True, verbose=1)\n",
        "]\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=150,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"Tiempo de entrenamiento: {training_time:.2f} segundos\")\n",
        "\n",
        "# Evaluar el modelo\n",
        "train_loss, train_acc = model.evaluate(train_images, train_labels, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
        "\n",
        "# Calcular y mostrar los errores\n",
        "train_error = 100 - train_acc * 100\n",
        "test_error = 100 - test_acc * 100\n",
        "\n",
        "print(f\"Entrenamiento. Accuracy: {train_acc * 100:.2f}% - Error: {train_error:.2f}%\")\n",
        "print(f\"Prueba. Accuracy: {test_acc * 100:.2f}% - Error: {test_error:.2f}%\")\n",
        "\n",
        "predictions = model.predict(test_images)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Imprimir 10000 dígitos y todos seguidos\n",
        "print(''.join(map(str, predicted_labels)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfWPGwyPredr",
        "outputId": "d9a7812e-8ece-4d49-8002-f60049edaeec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 0.14620, saving model to best_model.keras\n",
            "1500/1500 - 28s - 19ms/step - accuracy: 0.9222 - loss: 0.6920 - val_accuracy: 0.9774 - val_loss: 0.1462 - learning_rate: 5.0000e-04\n",
            "Epoch 2/150\n",
            "\n",
            "Epoch 2: val_loss improved from 0.14620 to 0.08948, saving model to best_model.keras\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9693 - loss: 0.1641 - val_accuracy: 0.9884 - val_loss: 0.0895 - learning_rate: 5.0000e-04\n",
            "Epoch 3/150\n",
            "\n",
            "Epoch 3: val_loss improved from 0.08948 to 0.08609, saving model to best_model.keras\n",
            "1500/1500 - 41s - 27ms/step - accuracy: 0.9732 - loss: 0.1404 - val_accuracy: 0.9884 - val_loss: 0.0861 - learning_rate: 5.0000e-04\n",
            "Epoch 4/150\n",
            "\n",
            "Epoch 4: val_loss improved from 0.08609 to 0.08513, saving model to best_model.keras\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9754 - loss: 0.1265 - val_accuracy: 0.9861 - val_loss: 0.0851 - learning_rate: 5.0000e-04\n",
            "Epoch 5/150\n",
            "\n",
            "Epoch 5: val_loss improved from 0.08513 to 0.07411, saving model to best_model.keras\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9781 - loss: 0.1167 - val_accuracy: 0.9899 - val_loss: 0.0741 - learning_rate: 5.0000e-04\n",
            "Epoch 6/150\n",
            "\n",
            "Epoch 6: val_loss improved from 0.07411 to 0.06568, saving model to best_model.keras\n",
            "1500/1500 - 25s - 17ms/step - accuracy: 0.9797 - loss: 0.1094 - val_accuracy: 0.9923 - val_loss: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 7/150\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.06568\n",
            "1500/1500 - 37s - 25ms/step - accuracy: 0.9806 - loss: 0.1049 - val_accuracy: 0.9908 - val_loss: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 8/150\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.06568\n",
            "1500/1500 - 39s - 26ms/step - accuracy: 0.9814 - loss: 0.1028 - val_accuracy: 0.9914 - val_loss: 0.0699 - learning_rate: 5.0000e-04\n",
            "Epoch 9/150\n",
            "\n",
            "Epoch 9: val_loss improved from 0.06568 to 0.06552, saving model to best_model.keras\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9819 - loss: 0.1010 - val_accuracy: 0.9926 - val_loss: 0.0655 - learning_rate: 5.0000e-04\n",
            "Epoch 10/150\n",
            "\n",
            "Epoch 10: val_loss improved from 0.06552 to 0.06439, saving model to best_model.keras\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9829 - loss: 0.0986 - val_accuracy: 0.9925 - val_loss: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 11/150\n",
            "\n",
            "Epoch 11: val_loss improved from 0.06439 to 0.06128, saving model to best_model.keras\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9831 - loss: 0.0976 - val_accuracy: 0.9923 - val_loss: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 12/150\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.06128\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9833 - loss: 0.0931 - val_accuracy: 0.9922 - val_loss: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 13/150\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.06128\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9834 - loss: 0.0945 - val_accuracy: 0.9920 - val_loss: 0.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 14/150\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.06128\n",
            "1500/1500 - 23s - 15ms/step - accuracy: 0.9848 - loss: 0.0902 - val_accuracy: 0.9928 - val_loss: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 15/150\n",
            "\n",
            "Epoch 15: val_loss improved from 0.06128 to 0.04428, saving model to best_model.keras\n",
            "1500/1500 - 38s - 25ms/step - accuracy: 0.9874 - loss: 0.0693 - val_accuracy: 0.9937 - val_loss: 0.0443 - learning_rate: 2.5000e-04\n",
            "Epoch 16/150\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.04428\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9882 - loss: 0.0644 - val_accuracy: 0.9937 - val_loss: 0.0452 - learning_rate: 2.5000e-04\n",
            "Epoch 17/150\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.04428\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9886 - loss: 0.0622 - val_accuracy: 0.9936 - val_loss: 0.0454 - learning_rate: 2.5000e-04\n",
            "Epoch 18/150\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.04428\n",
            "1500/1500 - 22s - 14ms/step - accuracy: 0.9891 - loss: 0.0602 - val_accuracy: 0.9935 - val_loss: 0.0491 - learning_rate: 2.5000e-04\n",
            "Epoch 19/150\n",
            "\n",
            "Epoch 19: val_loss improved from 0.04428 to 0.03460, saving model to best_model.keras\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9902 - loss: 0.0521 - val_accuracy: 0.9946 - val_loss: 0.0346 - learning_rate: 1.2500e-04\n",
            "Epoch 20/150\n",
            "\n",
            "Epoch 20: val_loss improved from 0.03460 to 0.03443, saving model to best_model.keras\n",
            "1500/1500 - 22s - 15ms/step - accuracy: 0.9914 - loss: 0.0465 - val_accuracy: 0.9948 - val_loss: 0.0344 - learning_rate: 1.2500e-04\n",
            "Epoch 21/150\n",
            "\n",
            "Epoch 21: val_loss improved from 0.03443 to 0.03394, saving model to best_model.keras\n",
            "1500/1500 - 41s - 27ms/step - accuracy: 0.9906 - loss: 0.0478 - val_accuracy: 0.9948 - val_loss: 0.0339 - learning_rate: 1.2500e-04\n",
            "Epoch 22/150\n",
            "\n",
            "Epoch 22: val_loss improved from 0.03394 to 0.03316, saving model to best_model.keras\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9912 - loss: 0.0455 - val_accuracy: 0.9956 - val_loss: 0.0332 - learning_rate: 1.2500e-04\n",
            "Epoch 23/150\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.03316\n",
            "1500/1500 - 22s - 14ms/step - accuracy: 0.9909 - loss: 0.0474 - val_accuracy: 0.9948 - val_loss: 0.0353 - learning_rate: 1.2500e-04\n",
            "Epoch 24/150\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.03316\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9914 - loss: 0.0451 - val_accuracy: 0.9947 - val_loss: 0.0339 - learning_rate: 1.2500e-04\n",
            "Epoch 25/150\n",
            "\n",
            "Epoch 25: val_loss improved from 0.03316 to 0.03225, saving model to best_model.keras\n",
            "1500/1500 - 22s - 15ms/step - accuracy: 0.9919 - loss: 0.0434 - val_accuracy: 0.9952 - val_loss: 0.0322 - learning_rate: 1.2500e-04\n",
            "Epoch 26/150\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.03225\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9917 - loss: 0.0430 - val_accuracy: 0.9952 - val_loss: 0.0323 - learning_rate: 1.2500e-04\n",
            "Epoch 27/150\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.03225\n",
            "1500/1500 - 23s - 15ms/step - accuracy: 0.9924 - loss: 0.0414 - val_accuracy: 0.9950 - val_loss: 0.0327 - learning_rate: 1.2500e-04\n",
            "Epoch 28/150\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.03225\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9917 - loss: 0.0430 - val_accuracy: 0.9949 - val_loss: 0.0322 - learning_rate: 1.2500e-04\n",
            "Epoch 29/150\n",
            "\n",
            "Epoch 29: val_loss improved from 0.03225 to 0.02787, saving model to best_model.keras\n",
            "1500/1500 - 22s - 15ms/step - accuracy: 0.9920 - loss: 0.0412 - val_accuracy: 0.9957 - val_loss: 0.0279 - learning_rate: 6.2500e-05\n",
            "Epoch 30/150\n",
            "\n",
            "Epoch 30: val_loss improved from 0.02787 to 0.02741, saving model to best_model.keras\n",
            "1500/1500 - 41s - 27ms/step - accuracy: 0.9927 - loss: 0.0389 - val_accuracy: 0.9958 - val_loss: 0.0274 - learning_rate: 6.2500e-05\n",
            "Epoch 31/150\n",
            "\n",
            "Epoch 31: val_loss improved from 0.02741 to 0.02704, saving model to best_model.keras\n",
            "1500/1500 - 22s - 14ms/step - accuracy: 0.9932 - loss: 0.0365 - val_accuracy: 0.9958 - val_loss: 0.0270 - learning_rate: 6.2500e-05\n",
            "Epoch 32/150\n",
            "\n",
            "Epoch 32: val_loss improved from 0.02704 to 0.02701, saving model to best_model.keras\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9925 - loss: 0.0372 - val_accuracy: 0.9952 - val_loss: 0.0270 - learning_rate: 6.2500e-05\n",
            "Epoch 33/150\n",
            "\n",
            "Epoch 33: val_loss improved from 0.02701 to 0.02629, saving model to best_model.keras\n",
            "1500/1500 - 20s - 14ms/step - accuracy: 0.9934 - loss: 0.0356 - val_accuracy: 0.9956 - val_loss: 0.0263 - learning_rate: 6.2500e-05\n",
            "Epoch 34/150\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.02629\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9933 - loss: 0.0344 - val_accuracy: 0.9953 - val_loss: 0.0275 - learning_rate: 6.2500e-05\n",
            "Epoch 35/150\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.02629\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9930 - loss: 0.0359 - val_accuracy: 0.9956 - val_loss: 0.0270 - learning_rate: 6.2500e-05\n",
            "Epoch 36/150\n",
            "\n",
            "Epoch 36: val_loss improved from 0.02629 to 0.02549, saving model to best_model.keras\n",
            "1500/1500 - 40s - 27ms/step - accuracy: 0.9930 - loss: 0.0364 - val_accuracy: 0.9958 - val_loss: 0.0255 - learning_rate: 6.2500e-05\n",
            "Epoch 37/150\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.02549\n",
            "1500/1500 - 41s - 28ms/step - accuracy: 0.9930 - loss: 0.0350 - val_accuracy: 0.9956 - val_loss: 0.0276 - learning_rate: 6.2500e-05\n",
            "Epoch 38/150\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.02549\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9928 - loss: 0.0349 - val_accuracy: 0.9955 - val_loss: 0.0258 - learning_rate: 6.2500e-05\n",
            "Epoch 39/150\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.02549\n",
            "1500/1500 - 22s - 15ms/step - accuracy: 0.9930 - loss: 0.0337 - val_accuracy: 0.9956 - val_loss: 0.0267 - learning_rate: 6.2500e-05\n",
            "Epoch 40/150\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.02549\n",
            "1500/1500 - 39s - 26ms/step - accuracy: 0.9935 - loss: 0.0329 - val_accuracy: 0.9953 - val_loss: 0.0262 - learning_rate: 3.1250e-05\n",
            "Epoch 41/150\n",
            "\n",
            "Epoch 41: val_loss improved from 0.02549 to 0.02484, saving model to best_model.keras\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9932 - loss: 0.0324 - val_accuracy: 0.9953 - val_loss: 0.0248 - learning_rate: 3.1250e-05\n",
            "Epoch 42/150\n",
            "\n",
            "Epoch 42: val_loss improved from 0.02484 to 0.02415, saving model to best_model.keras\n",
            "1500/1500 - 22s - 15ms/step - accuracy: 0.9939 - loss: 0.0312 - val_accuracy: 0.9961 - val_loss: 0.0242 - learning_rate: 3.1250e-05\n",
            "Epoch 43/150\n",
            "\n",
            "Epoch 43: val_loss improved from 0.02415 to 0.02404, saving model to best_model.keras\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9937 - loss: 0.0319 - val_accuracy: 0.9955 - val_loss: 0.0240 - learning_rate: 3.1250e-05\n",
            "Epoch 44/150\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.02404\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9935 - loss: 0.0311 - val_accuracy: 0.9958 - val_loss: 0.0241 - learning_rate: 3.1250e-05\n",
            "Epoch 45/150\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.02404\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9944 - loss: 0.0302 - val_accuracy: 0.9954 - val_loss: 0.0253 - learning_rate: 3.1250e-05\n",
            "Epoch 46/150\n",
            "\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.02404\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9933 - loss: 0.0319 - val_accuracy: 0.9958 - val_loss: 0.0242 - learning_rate: 3.1250e-05\n",
            "Epoch 47/150\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.02404\n",
            "1500/1500 - 20s - 14ms/step - accuracy: 0.9938 - loss: 0.0304 - val_accuracy: 0.9955 - val_loss: 0.0242 - learning_rate: 1.5625e-05\n",
            "Epoch 48/150\n",
            "\n",
            "Epoch 48: val_loss improved from 0.02404 to 0.02378, saving model to best_model.keras\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9945 - loss: 0.0296 - val_accuracy: 0.9957 - val_loss: 0.0238 - learning_rate: 1.5625e-05\n",
            "Epoch 49/150\n",
            "\n",
            "Epoch 49: val_loss improved from 0.02378 to 0.02348, saving model to best_model.keras\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9941 - loss: 0.0292 - val_accuracy: 0.9957 - val_loss: 0.0235 - learning_rate: 1.5625e-05\n",
            "Epoch 50/150\n",
            "\n",
            "Epoch 50: val_loss improved from 0.02348 to 0.02343, saving model to best_model.keras\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9947 - loss: 0.0280 - val_accuracy: 0.9958 - val_loss: 0.0234 - learning_rate: 1.5625e-05\n",
            "Epoch 51/150\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.02343\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9937 - loss: 0.0299 - val_accuracy: 0.9956 - val_loss: 0.0236 - learning_rate: 1.5625e-05\n",
            "Epoch 52/150\n",
            "\n",
            "Epoch 52: val_loss improved from 0.02343 to 0.02328, saving model to best_model.keras\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9943 - loss: 0.0281 - val_accuracy: 0.9956 - val_loss: 0.0233 - learning_rate: 1.5625e-05\n",
            "Epoch 53/150\n",
            "\n",
            "Epoch 53: val_loss improved from 0.02328 to 0.02321, saving model to best_model.keras\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9939 - loss: 0.0293 - val_accuracy: 0.9956 - val_loss: 0.0232 - learning_rate: 1.5625e-05\n",
            "Epoch 54/150\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.02321\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9942 - loss: 0.0283 - val_accuracy: 0.9957 - val_loss: 0.0235 - learning_rate: 1.5625e-05\n",
            "Epoch 55/150\n",
            "\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.02321\n",
            "1500/1500 - 19s - 13ms/step - accuracy: 0.9941 - loss: 0.0290 - val_accuracy: 0.9955 - val_loss: 0.0233 - learning_rate: 1.5625e-05\n",
            "Epoch 56/150\n",
            "\n",
            "Epoch 56: val_loss improved from 0.02321 to 0.02308, saving model to best_model.keras\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9944 - loss: 0.0276 - val_accuracy: 0.9957 - val_loss: 0.0231 - learning_rate: 7.8125e-06\n",
            "Epoch 57/150\n",
            "\n",
            "Epoch 57: val_loss improved from 0.02308 to 0.02287, saving model to best_model.keras\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9946 - loss: 0.0277 - val_accuracy: 0.9957 - val_loss: 0.0229 - learning_rate: 7.8125e-06\n",
            "Epoch 58/150\n",
            "\n",
            "Epoch 58: val_loss improved from 0.02287 to 0.02284, saving model to best_model.keras\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9943 - loss: 0.0285 - val_accuracy: 0.9957 - val_loss: 0.0228 - learning_rate: 7.8125e-06\n",
            "Epoch 59/150\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.02284\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9944 - loss: 0.0280 - val_accuracy: 0.9954 - val_loss: 0.0232 - learning_rate: 7.8125e-06\n",
            "Epoch 60/150\n",
            "\n",
            "Epoch 60: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.02284\n",
            "1500/1500 - 41s - 27ms/step - accuracy: 0.9944 - loss: 0.0276 - val_accuracy: 0.9956 - val_loss: 0.0230 - learning_rate: 7.8125e-06\n",
            "Epoch 61/150\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.02284\n",
            "1500/1500 - 41s - 27ms/step - accuracy: 0.9946 - loss: 0.0273 - val_accuracy: 0.9952 - val_loss: 0.0231 - learning_rate: 3.9063e-06\n",
            "Epoch 62/150\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.02284\n",
            "1500/1500 - 40s - 27ms/step - accuracy: 0.9945 - loss: 0.0266 - val_accuracy: 0.9955 - val_loss: 0.0230 - learning_rate: 3.9063e-06\n",
            "Epoch 63/150\n",
            "\n",
            "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.02284\n",
            "1500/1500 - 20s - 13ms/step - accuracy: 0.9942 - loss: 0.0274 - val_accuracy: 0.9954 - val_loss: 0.0231 - learning_rate: 3.9063e-06\n",
            "Epoch 64/150\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.02284\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9944 - loss: 0.0279 - val_accuracy: 0.9955 - val_loss: 0.0231 - learning_rate: 1.9531e-06\n",
            "Epoch 65/150\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.02284\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9941 - loss: 0.0280 - val_accuracy: 0.9956 - val_loss: 0.0229 - learning_rate: 1.9531e-06\n",
            "Epoch 66/150\n",
            "\n",
            "Epoch 66: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.02284\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9944 - loss: 0.0275 - val_accuracy: 0.9956 - val_loss: 0.0228 - learning_rate: 1.9531e-06\n",
            "Epoch 67/150\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.02284\n",
            "1500/1500 - 21s - 14ms/step - accuracy: 0.9946 - loss: 0.0269 - val_accuracy: 0.9956 - val_loss: 0.0229 - learning_rate: 1.0000e-06\n",
            "Epoch 68/150\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.02284\n",
            "1500/1500 - 39s - 26ms/step - accuracy: 0.9940 - loss: 0.0279 - val_accuracy: 0.9954 - val_loss: 0.0230 - learning_rate: 1.0000e-06\n",
            "Epoch 68: early stopping\n",
            "Restoring model weights from the end of the best epoch: 58.\n",
            "Tiempo de entrenamiento: 1662.53 segundos\n",
            "Entrenamiento. Accuracy: 99.79% - Error: 0.21%\n",
            "Prueba. Accuracy: 99.72% - Error: 0.28%\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "7210414959069015973496654074013134727121174235124463556041957893746430702917329776278473613693141769605499219487397444925476790585665781016467317182029955156034465465451447232718181850892501110803164236111395294593903655722712841733887922415987230442419577282685779181803019941821297592641582920400284712402743300319652592930420711215339786561381051315561851794622506563720885411403376162192861952544283824503177579719214292049148184598837600302664933323912680566638827589618412591975408991052378940639521313657422632654897130383193446421825488400232770874479690980460635483393337802217065438096380996868578602402231975108462679329822927359180205213767125803724091867743491951739769137833672858511443107707944855408210845040617326726931462542062173410543117499484024511647194241553831456894153803251283440883317359632613607217142421796112481774807313107703552766928352256082928888744306632132293005781446029147473988471212232323917403558632676632791175649513347891169144540622315120381267162390122089902519781041795426813754418138125806211115346950922482172494403922338357358124464951069595973803713678597969637445354787807688733195273511214747545408369602744446647934558737270241166928720150917060868180337236216113790805402872984045851213174572098862541921587024436882405044793415973588053366016035441291469939844313188794887971456052221552496277221128372417176782731758262256509243397668041582918067210552022024980994654918349912281964094838602519629409606254238455038535865763396112904336957377787983072794549321402375788501148390006623784779241452499184098487707886048824766647188236300376979954336123733203384363502690746935196145450595212919940845292121736884919857511865244323568862310589296704871741097200917878472046031133967413308739693502745175808815030314037271807043198771499321790203376923377007529874426619682908311635111312302013557489696836685142445119024957188569871167632208925108145796906155838265074613473234252717264157860182577693584240883492758656086736494663241014629110639565658464391341917119354073617553301575865104234679818492862700675860937135433556302342309947284706285285730823282557646848274520399672561123678764894863831062256958141784618431280859142027090257679426244804458068985690487134580913369871057175279185249472234919217944167278819711753351376138759900288237130344389239711704965917020046707146454991795338236221111169843716450474240701988600496822384822175440439731012592101891683893628322104292437915249038536094625007466866869172599072767065247209922944233217076413874592518737155091406336049751689557938381535055386777370590255317786593895379170037238186295757862514845830627332107340393289038076547390862511004401232778525769141642435439501538919795527460111044763004306196138125627360197668929583100766216931869060006359345585304029682312115698066553862145437850935110447017016145665784472537077964285783958998628923611893407964141349314774729308884044152834952815379425635935931953069840492901031658153303559287049197755209186239621913550383376601406981299597378013046102584411546606926271794003822316057792679786884684128139403732337340620815354171575732273737854525653674171523631426743806216539193218446586977869739405464123002665708647907342188592718882760127108360536287014211444471629900188434206161222123781002166016251748214383994834727570433267600677055810702815088032772647555292846865008761711274007763864209405782747113662919483695962467706694835349005250711107679664143112241087634006330717113109975414895351982339901029393362498374047849899759282202238468682467933943144705960444461233645968565864186528455477078223701807198755917549122166711407424064769534650188283578085711013785071101145276230285969721364182405102264439616579202601435288088909676393477749064842728100783331376131665747595849916501370348220251514889121351094483259766200058715238518204996233564809283675729491286070911675991959250410890898942579898099689959851033521650281562302264355172169199551622867146040332236898538545205632839957946713736609019928801697534749943631176918411994568160413774951001162198403649071657525185470670258104571851900607318397008959832729721137531982228857389886823975629288168879180172075190209862393802111142977511219991020211464154977156222806961977148534349750748815395976903639822128685539492515144144359122330290099609328419972799595118351953549593190975492010514933615252209266012030255795508950325908845884548549221268870366438872200939919866426928545799921834078393465623926006128798204775056467430750742089942467876941373088769392292183296840128452781130357031936317730848265297390996429721167475968214457613259936114697215146381103168490730290666367728608302983253880019513960141712379749939282718091017796999216135719764576699636298122552372101045282835178112978405078847785849813803174551657493547120816073473960864877938697234021835572467283087890844585663093768934958912886813790119708174571211396212807669370528054384662795132436194476541992780136134111560707232522949812161278000822922799275134941856283128499370772324039984106096861198923559421943960406012347890123478901234567898347863409719384730914546206211117247529458429700751176668227740242189610596980308396301234567012345678901234567854874773988315827421545586444187551891363322699655338165681976837470900379302010104010479626229901234567890123456789012345678980566080237947191714004175713331697430252608943548159064363381475722001779598968823612989526248465015678901234567890123456789742090158802784461045394205013291601180477636073542418356706712581938287671462930123456701234501289140950807711293672381298871711034264742749106855535974859693038918160012345678901234567890123456789353293214552351397212891887810027875061574612507990384481865900037164266045413863995937856476220940123456789012356012345687132807599609413212383265682748180539419219679046173872965839057161093344062542346002014567890123456780123456789871375280759909115886321832656741053192196046173872965835716109625423446002012345678901234567890128456789865068941953048914055215407601706895179860817713231420078464938472563696322469025513397872257982131301234567890123456789012345678912653070414367231212960130275762919060602061584301544857578348852971381075969477993443862012345678901234567890123456789083955268491712359691112956812077582989046713456036870427475434281512025643000335706488634699827710123456789012345678012345678217250802788360276612887747737454338411974373302556635259984106096885611989235594219392060400123478901237890123478973031876402683281207104458062315185940758838926253173919960392814352925895012456012345671234510456634428106497233920933915231784024024780706932860575108167297958626281750113449186890123456789012347890178998984177337666190176321713917684143696144724401234567890123456901234781351772148344397412359160100287114047368037406926586904061920951376930220123456789012345678901234567892172508027883060276612887747737454338454119743733025563152599841060968856119892355942194913920604060123456789012345678901234567893807107556901008343150095349376924572649494122581329438221286516721393875707488506637699484106601234567890123456789012345678974040179514289437824433699586706826393286174889033905294103758778297126425236650028161043161901456789123456701234567898400724386632633014780319019127013829276559982913234319093687010582770123456789012345678901234567891748156572863386540917291513223064376904814061269223551077962947023400888513749889098902656747541353123456123460124567817241414968453784335670616870150850158423976919067123924553753182230294970274992598386700123456789012345678901234567890072655378666643883019054191270138292742655991157682943190936870105827701234567890123458901234567892121399853707757994703415814841866460553357259692621208383087495097004609162768352183861021401234567890123456789012345678976476234878698322848565020112968210652975393718381955011982604503186759930314404901235678012356789012356789970901588093278461049420501693291601187763607241706712581828768716293012345678901234567890123456789895703168415642781343472050192323557849971190783486380962101062389072345528546667918215347940001234567890123456789012345690131512492468011926687429702103601234567890123456789012345678986597023438515230121326530727464059989531747654006620637744392896095388714048523901915174862168801234789012346789012347891453309543084670771691362382389588717110342647427429279210653485969063081600123456701234789012347251643990971643620986570017432413764777984352835805471317962091733916439821864155650123456789012345678901234567896970234385130121320726405998953174700666374289871404852390191517612168012345678901234567801235678104566344281064972920933915231673784024024780706932486057510816729795652628175573501138494518689012345678901234567890123456789353293214552321397212891887810067787506157461250799034484186590003716460454138639959378564762209401234567890123456789012345678964264755472939382095601065353800341530830627817138542097674162671980694996237192253780123478901234789017898926135482643459203949738744985826623132731901135078151460049166907611012347234567012786397193961724457001668277242161069839630123456789012345678901234567891689901244374440387582175385251162138642625502806817919267668749213305580379702791780353601234567890123456789012347896426478929393001042635303415308306178092671969499671253780124567890134567801347897551997100597172236832006175862948871087758534611550723641241542048619025693636012345678901234567890123567810957518690419384470192878259606553339811061006211327788784602070368715993724943622532559417201234567890123456789012345678910127534400696657234491407957231440996183373988477621987887223933550795651411282615012345678901234567890123456788060023794719171400175713331697130260894354815906638147520017876882361295201234567890123456789012346678974614099378475853220586038103047492957171665628764995374304661132100123478901234567801234789083955268417123569111212077582986734687042775434281510233570686399827710178901234567801234789786419384470192878260653339140610062117784607036871524943641726501234567890123456\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}